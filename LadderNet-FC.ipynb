{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LadderNet-FC.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"r4eWLWJ0mBzL","colab_type":"code","colab":{}},"cell_type":"code","source":["class DataSet:\n","  \n","  def __init__(self,X,y,X_validate,y_validate,X_test,y_test,batch_size=100,architecture=None,denoising_cost=None,\n","               validate=True,name=None, num_labeled=-1, X_unlabeled = None):\n","    \n","    import os; os.environ['KERAS_BACKEND'] = 'theano'\n","    from keras.utils import to_categorical\n","    #Convert to one hot encoding. Same goes for y_test\n","    self._num_labeled = num_labeled\n","    self._validate = validate\n","    if X_unlabeled is not None:\n","      self._X_unlabeled = X_unlabeled #This is for the case we have truly unlabeled data\n","      self._X_labeled = X\n","      self._y_labeled = to_categorical(y)\n","    else: self._X_unlabeled = None\n","    \n","    if name is not None:\n","      self._name = name\n","    else: self._name = 'Unknown'\n","    \n","    self._orig_y = y\n","    self._y = to_categorical(y)\n","    self._y_test = to_categorical(y_test)\n","    self._num_examples = X.shape[0]\n","    self._X = X\n","    \n","    if not validate:\n","      self._X_validate = X_test\n","      self._y_validate = to_categorical(y_test)\n","    else:\n","      self._X_validate = X_validate\n","      self._y_validate = to_categorical(y_validate)\n","      \n","    self._X_test = X_test\n","    \n","    self._current_epoch = 0 #Keep track of the epoch\n","    self._batch_size = batch_size\n","    self._curr_index = 0 #This index keeps track of position in the training data\n","    self._idx = np.arange(0,len(y))\n","    \n","    if architecture is None:\n","      self._architecture = [X.shape[1], 500, 250, self._y.shape[1]]\n","    else:\n","      self._architecture = architecture\n","      \n","    if denoising_cost is None:\n","      self._denoising_cost = [1000.0, 0.10, 0.10, 0.10]\n","    else:\n","      self._denoising_cost = denoising_cost\n","      \n","      \n","    if num_labeled != -1 and X_unlabeled is None:\n","      #Generate a dataset that is labeled and fixed and the rest is an unlabeled dataset\n","      #For simplicity, when num_labeled = 100, we set aside 100 lab. examples for validation\n","      #and testing respectively. So it truly corresponds to 100 labeled training examples, but\n","      #we still need data to verify the model.\n","      n_classes = len(np.unique(self._orig_y))\n","      n_from_each_class = int(num_labeled/n_classes)\n","      indices = np.arange(len(self._y))\n","      i_labeled = []\n","      for c in range(n_classes):\n","            i = indices[self._orig_y==c][:n_from_each_class]\n","            i_labeled += list(i)\n","      \n","\n","      self._X_labeled = self._X[i_labeled,:]\n","      self._y_labeled = self._y[i_labeled,:]\n","      \n","      #Sanity check balance\n","      '''import matplotlib.pyplot as plt\n","      plt.hist(self._orig_y[i_labeled])\n","      plt.show()'''\n","      \n","      #Take everything as unlabeled data\n","      self._X_unlabeled = self._X\n","    \n","  def next_batch(self):\n","    if self._num_labeled == -1:\n","      if self._curr_index + self._batch_size < self._X.shape[0]: #shape (numEx,Dim)\n","        idx = self._idx[self._curr_index:self._curr_index+self._batch_size]\n","        X_b = self._X[idx]\n","        y_b = self._y[idx]\n","        self._curr_index = self._curr_index + self._batch_size\n","      else:\n","        #Shuffle data and set current index to batch size\n","        self._current_epoch = self._current_epoch + 1\n","        np.random.shuffle(self._idx)\n","        idx = self._idx[0:self._batch_size]\n","        self._curr_index = self._batch_size\n","        X_b = self._X[idx]\n","        y_b = self._y[idx]\n","      return (X_b,y_b)\n","    \n","    else:\n","      #We want to return a stack of labeled and unlab. datapoints. In that case, the labeled images\n","      #must be drawn evenly distributed from each class\n","      if self._batch_size > self._num_labeled: #Take all the labeled data points\n","        idx = np.arange(self._num_labeled)\n","        np.random.shuffle(idx)\n","        X_l = self._X_labeled[idx,:]\n","        y_l = self._y_labeled[idx]\n","      else:\n","        idx = np.arange(self._num_labeled)\n","        np.random.shuffle(idx)\n","        idx = idx[:self._batch_size]\n","        X_l = self._X_labeled[idx,:]\n","        y_l = self._y_labeled[idx]\n","        \n","      idx_ul = np.arange(self._X.shape[0])\n","      np.random.shuffle(idx_ul)\n","      idx_ul = idx_ul[:self._batch_size]\n","      X_ul = self._X_unlabeled[idx_ul,:]\n","      \n","      X_b = np.vstack([X_l, X_ul])\n","      return (X_b,y_l)\n","  \n","  @property\n","  def train(self):\n","    return (self._X, self._y)\n","  \n","  @property\n","  def validate(self):\n","    return (self._X_validate, self._y_validate)\n","  \n","  @property\n","  def test(self):\n","    return (self._X_test, self._y_test)\n","  \n","  @property\n","  def batch_size(self):\n","    return self._batch_size\n","  \n","  @property\n","  def num_examples(self):\n","    return self._num_examples\n","  \n","  @property\n","  def architecture(self):\n","    return self._architecture\n","  \n","  @property\n","  def denoising_cost(self):\n","    return self._denoising_cost\n","  \n","  @property\n","  def name(self):\n","    return self._name\n","  @property\n","  def num_labeled(self):\n","    return self._num_labeled\n","  @property\n","  def use_validate(self):\n","    return self._validate\n","  \n","  def diff(self,first, second):\n","    second = set(second)\n","    return [item for item in first if item not in second]\n","  \n","  \n","  \n","  #Class that stores multiple data sets\n","class DataSets:\n","  def __init__(self):\n","    self.datasets = []\n","    self.current = 0\n","    \n","  def add(self,ds):\n","    self.datasets.append(ds)\n","    \n","  def get_next(self):\n","    if self.current == len(self.datasets):\n","      print(\"No more datasets.\")\n","      return False\n","    else:\n","      self.current += 1\n","      return self.datasets[self.current - 1]\n","    \n","  def get_dataset(self,name=None):\n","    if name is not None:\n","      for ds in self.datasets:\n","        if ds.name.lower() == name.lower():\n","          return ds\n","      \n","    else: return self.datasets[0]\n","    \n","    \n","    \n","    \n","    "],"execution_count":0,"outputs":[]},{"metadata":{"id":"VL3MVErVmMtG","colab_type":"code","outputId":"7f81d1e2-f520-4383-8cb2-cf4188d55e4b","executionInfo":{"status":"ok","timestamp":1542900997735,"user_tz":300,"elapsed":3196,"user":{"displayName":"Julian Büchel","photoUrl":"https://lh3.googleusercontent.com/-bqF5uYHav44/AAAAAAAAAAI/AAAAAAAAABI/I52w6WAUfGc/s64/photo.jpg","userId":"08269725658623338909"}},"colab":{"base_uri":"https://localhost:8080/","height":84}},"cell_type":"code","source":["import numpy as np\n","from sklearn.decomposition import PCA\n","import scipy.io as sio\n","from sklearn.model_selection import train_test_split\n","from sklearn import preprocessing\n","import os\n","import random\n","from random import shuffle\n","from skimage.transform import rotate\n","import scipy.ndimage\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","import scipy\n","!pip install GoogleDriveDownloader\n","from google_drive_downloader import GoogleDriveDownloader as gdd\n","\n","def load_pavia():\n","  \n","  gdd.download_file_from_google_drive(file_id='146WN2eZ6Syf-z1KMVRw9GmZdBu_g1JBj',\n","                                    dest_path='./datasets/paviau.mat', unzip=False)\n","\n","  gdd.download_file_from_google_drive(file_id='1L9OoAHnLVmPGbfKx8NhEbugxMzE1PG4j',\n","                                    dest_path='./datasets/paviau_gt.mat', unzip=False)\n","\n","  X = sio.loadmat('./datasets/paviau.mat')['paviaU']\n","  y = sio.loadmat('./datasets/paviau_gt.mat')['paviaU_gt']\n","\n","  return X, y\n","\n","  \n","  \n","def load_salinas():\n","  gdd.download_file_from_google_drive(file_id='1DfBTXkd-02MhEpP8dA_rtjvTIdW2d-15',\n","                                    dest_path='./datasets/salinas.mat', unzip=False)\n","\n","  gdd.download_file_from_google_drive(file_id='1Rb9UKxO1okkzUsTfCcF1CzoGA2IEiUDR',\n","                                    dest_path='./datasets/salinas_gt.mat', unzip=False)\n","\n","  X = sio.loadmat('./datasets/salinas.mat')['salinas_corrected']\n","  y = sio.loadmat('./datasets/salinas_gt.mat')['salinas_gt']\n","\n","  return X, y "],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting GoogleDriveDownloader\n","  Downloading https://files.pythonhosted.org/packages/7e/41/d59b2a5fcc7afeb40f23091694bd6e6a63ad118c93f834353ee5100285d5/googledrivedownloader-0.3-py2.py3-none-any.whl\n","Installing collected packages: GoogleDriveDownloader\n","Successfully installed GoogleDriveDownloader-0.3\n"],"name":"stdout"}]},{"metadata":{"id":"mq2Wt1YBmUof","colab_type":"code","colab":{}},"cell_type":"code","source":["#Returns dataset with the given hyperparameters\n","def preprocess_data(name, numComponents, architecture, denoising_cost,batch_size,num_labeled):\n","  \n","  if name == 'pavia':\n","    X,y = load_pavia()\n","    n_each = 947\n","    n_classes = 9\n","  else:\n","    X,y = load_salinas()\n","    n_each = 916\n","    n_classes = 16\n","  \n","  #Reshape\n","  X = np.reshape(X, [-1,X.shape[2]])\n","  y = np.reshape(y, [-1])\n","    \n","  idx = np.arange(len(y))\n","  idx = idx[(y != 0)]\n","  \n","  X = X[idx,:]\n","  y = y[idx]-1\n","  \n","  #Shuffle the data\n","  idx = np.arange(len(y))\n","  np.random.shuffle(idx)\n","  X = X[idx,:]\n","  y = y[idx]\n","  \n","  #Scale the data\n","  scaler = StandardScaler()\n","  scaler.fit(X)\n","  X = scaler.transform(X)\n","  \n","  if numComponents != -1:\n","    pca = PCA(n_components=numComponents, whiten=True)\n","    X = pca.fit_transform(X)\n","    \n","  #Downsample\n","  indices = np.arange(len(y))\n","  i_labeled = []\n","  for j in range(n_classes):\n","    i = indices[y == j][:n_each]\n","    i_labeled += list(i)\n","  \n","  y = y[i_labeled]\n","  X = X[i_labeled,:]\n","    \n","  X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25)\n","  \n","  return DataSet(X_train,y_train,None,None,X_test,y_test,batch_size=batch_size,\n","                    architecture=architecture,denoising_cost=denoising_cost,validate=False,name=name,num_labeled = num_labeled)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7skhlLhbwIwV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"019e38c7-ae53-44db-d592-16ac3d872cfb","executionInfo":{"status":"ok","timestamp":1542901032027,"user_tz":300,"elapsed":7213,"user":{"displayName":"Julian Büchel","photoUrl":"https://lh3.googleusercontent.com/-bqF5uYHav44/AAAAAAAAAAI/AAAAAAAAABI/I52w6WAUfGc/s64/photo.jpg","userId":"08269725658623338909"}}},"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","import math\n","import os; os.environ['KERAS_BACKEND'] = 'theano'\n","from keras.utils import to_categorical\n","#from tqdm import tqdm\n","\n","#Split the data in validation and training data\n","from sklearn.model_selection import train_test_split\n","\n","class LadderNetwork:\n","  def __init__(self,id):\n","    self._id = id\n","  \n","  \n","  def delete_checkpoints(self):\n","    c = str(self._id)\n","    import shutil\n","    import os\n","    if os.path.exists(c + '_checkpoints/') and os.path.isdir(c + '_checkpoints/'):\n","        shutil.rmtree(c + '_checkpoints/')\n","        \n","  def delete_models(self):\n","    c = str(self._id)\n","    import shutil\n","    import os\n","    if os.path.exists(c + '_models/') and os.path.isdir(c + '_models/'):\n","        shutil.rmtree(c + '_models/')\n","  \n","  \n","  def get_latest_meta(self):\n","    c = str(self._id)\n","    from os import listdir\n","    from os.path import isfile, join\n","    onlyfiles = [f for f in listdir(c + '_checkpoints/') if isfile(join(c + '_checkpoints/', f))]\n","    for name in onlyfiles:\n","      if name.lower().endswith('.meta'):\n","        if int(list(filter(str.isdigit, name))[0]) == int(list(filter(str.isdigit, tf.train.latest_checkpoint(c + '_checkpoints/')))[1]):\n","          return c + '_checkpoints/' + name\n","        \n","        \n","  def get_misclassified(self,X,y,y_cl=None):\n","    if y_cl is None:\n","      y_hat = self.predict(X)\n","      idx = np.arange(len(y_hat))[(y_hat != y)]\n","      return (X[idx,:], y[idx], y_hat[idx], idx)\n","    else: \n","      idx = np.arange(len(y_cl))[(y_cl != y)]\n","      return (X[idx,:], y[idx], y_hat[idx], idx)\n","    \n","  def fit(self,X_train,y_train,X_validate,y_validate,X_test,y_test,architecture,denoising_cost,num_epochs=150,batch_size=100,\n","            num_labeled=-1,noise_std=0.3,lr=0.02,decay_after=15,validate=True):\n","    if validate:\n","      data = DataSet(X_train,y_train,X_validate,y_validate,X_test,y_test,batch_size,architecture,denoising_cost)\n","    else:\n","      data = DataSet(X_train,y_train,None,None,X_test,y_test,batch_size,architecture,denoising_cost,validate=False)\n","    self.train(data,num_epochs,num_labeled,noise_std,lr,decay_after)\n","  \n","  \n","  #Returns accuracy of the trained model\n","  def train(self,data,num_epochs=150,num_labeled=-1,noise_std=0.3,lr=0.02,decay_after=15):\n","        tf.reset_default_graph()\n","        batch_size = data.batch_size\n","        \n","        architecture = data.architecture\n","        denoising_cost = data.denoising_cost\n","        \n","        #Create placeholders. They will be assigned when we start the session with feed_dict{...}\n","        inputs = tf.placeholder(tf.float32, shape=(None, architecture[0]), name='inputs')\n","        outputs = tf.placeholder(tf.float32, name='outputs')\n","\n","        #This is used to manage different checkpoint/model repositories\n","        c = str(self._id)\n","        \n","        #Number of layers\n","        L = len(architecture)-1\n","        n_examples = data.num_examples\n","                \n","        num_iter = (n_examples//batch_size) * num_epochs \n","\n","        '''For each layer, we need to keep track of: W the weights for the encoder, V the weights for the decoder\n","        beta a vector for the encoder, gamma a vector for the encoder, for each neuron in each layer of the decoder\n","        a 10 size vector A, for the denoising function (the lateral connection)'''\n","\n","        def vec_init(inits, size, name): #This is for beta and gamma vector in the encoding phase\n","          return tf.Variable(inits * tf.ones([size]), name=name)\n","\n","        def mat_init(shape, name): #Use this to initialize the weight matrices, initially random (normal)\n","          return tf.Variable(tf.random_normal(shape, name=name)) / math.sqrt(shape[0]) \n","\n","        #The following produces e.g. (784, 1000),(1000, 500),...,(250, 10)\n","        shapes = list(zip(list(architecture)[:-1], list(architecture[1:])))\n","\n","        #Initialize a dictionary of the weights. This makes it easy to keep track of the different dimensions and keep\n","        #Them in one data structure\n","        weights = {'W': [mat_init(s, \"W\") for s in shapes],\n","                 'V': [mat_init(s[::-1], \"V\") for s in shapes],\n","                 # batch normalization parameter to shift the normalized value\n","                 'beta': [vec_init(0.0, architecture[l+1], \"beta\") for l in range(L)],\n","                 # batch normalization parameter to scale the normalized value\n","                 'gamma': [vec_init(1.0, architecture[l+1], \"beta\") for l in range(L)]}\n","\n","\n","        #Some helper functions\n","        join = lambda l, u: tf.concat([l, u], 0)\n","        labeled = lambda x: tf.slice(x, [0, 0], [batch_size, -1]) if x is not None else x\n","        unlabeled = lambda x: tf.slice(x, [batch_size, 0], [-1, -1]) if x is not None else x\n","        split_lu = lambda x: (labeled(x), unlabeled(x))\n","\n","        #Placeholder for a boolean variable if we are training or not\n","        training = tf.placeholder(tf.bool,name='training')\n","\n","        #This keeps a moving average of the layers std and mean. This is valuable if the input is clean.\n","        #If the input is corrupted, we have to use the nn.moment variant to approximate the std and mean.\n","        ewma = tf.train.ExponentialMovingAverage(decay=0.99)  # to calculate the moving averages of mean and variance\n","        bn_assigns = []  # this list stores the updates to be made to average mean and variance\n","\n","        #Normalize the batch. This is used for non-clear inputs.\n","        def batch_normalization(batch, mean=None, var=None):\n","          if mean is None or var is None:\n","              mean, var = tf.nn.moments(batch, axes=[0])\n","          return (batch - mean) / tf.sqrt(var + tf.constant(1e-10))\n","\n","        #Average mean and variance of all layers for the labeled data. When we only have 100 labeled data in total\n","        #The batch var and mean is not enough. This is why we have to update the mean and std for the labeled data.\n","        #Use this var and mean for batch normalization later\n","        running_mean = [tf.Variable(tf.constant(0.0, shape=[l]), trainable=False) for l in architecture[1:]]\n","        running_var = [tf.Variable(tf.constant(1.0, shape=[l]), trainable=False) for l in architecture[1:]]\n","\n","        #Batch normalize + update average mean and variance of layer l\n","        def update_batch_normalization(batch, l):\n","          mean, var = tf.nn.moments(batch, axes=[0])\n","          assign_mean = running_mean[l-1].assign(mean)\n","          assign_var = running_var[l-1].assign(var)\n","          bn_assigns.append(ewma.apply([running_mean[l-1], running_var[l-1]]))\n","          with tf.control_dependencies([assign_mean, assign_var]):\n","              return (batch - mean) / tf.sqrt(var + 1e-10)\n","\n","\n","        '''Now define the encoder.\n","        The encoder serves as a noise introducing and clean encoder. At each leavel, we do the following:\n","\n","        For the corrupted case:\n","        Assign the z0 <- x(n)+noise then h0 <- z0 (no batch normalization)\n","        For all the layers:\n","        zl = batchnorm(W*hl-1)+noise /// hl <- actvation(gamma had.prod. (zl+beta))\n","        At the end: Output y <-hL, we use the corruped output for the cost (this serves as regularization)\n","\n","        For the clean encoder:\n","        z0 <- x(n) then h0 <- z0\n","        For all layers:\n","        z_pre_l <- Wl*h(l-1) //// mean(l) <- batchmean(z_pre_l) /// std(l) <- batchstd(z_pre_l) //// z_l <- batchnorm(z_pre)\n","        h_l <- activation(gamma had.prod. (z_l + beta))\n","        The Mean and std are used for batch normalisation in the decoder\n","        h is used as the input to the next layer and the final classification\n","        z is used for the cost function. We want to min. ||z_clean - z_noisy_recond|| for all layers\n","        '''\n","        def encoder(inputs,noise_std):\n","          h = inputs + tf.random_normal(tf.shape(inputs)) * noise_std #Clean input if the noise std is set to zero\n","          d = {} #Store normalized preactivation z_l, h_l, mean, std\n","\n","          #Initialize the dictionary that stores the data. Note that the data is stored seperately\n","          #The speration is because we still want to know for which examples we have the labels\n","          d['labeled'] = {'z': {}, 'm': {}, 'v': {}, 'h': {}}\n","          d['unlabeled'] = {'z': {}, 'm': {}, 'v': {}, 'h': {}}\n","\n","          #Initialize the lowest layer with h. We do not have a transformation there.\n","          d['labeled']['z'][0], d['unlabeled']['z'][0] = split_lu(h)\n","\n","          #Loop through all the layers. Doing forward propagation and updating the values we need to keep track of.\n","          for l in range(1, L+1): #Max. index: L\n","\n","              #Split the data that was joined before (TODO: Check if this can be done at end of loop)\n","              d['labeled']['h'][l-1], d['unlabeled']['h'][l-1] = split_lu(h)\n","              #Calculate the preactivation\n","              z_pre = tf.matmul(h, weights['W'][l-1])\n","              #Split into labeled and unlabeled examples\n","              z_pre_l, z_pre_u = split_lu(z_pre)\n","              #Caculate the mean and variance of the unlabeled examples, this is needed in the decoder phase when normalizing the \n","              m, v = tf.nn.moments(z_pre_u, axes=[0])\n","\n","              def training_batch_norm():\n","                  # Training batch normalization\n","                  # batch normalization for labeled and unlabeled examples is performed separately\n","                  if noise_std > 0:\n","                      # Corrupted encoder, do not update the mean and std of the layer\n","                      # batch normalization + noise\n","                      z = join(batch_normalization(z_pre_l), batch_normalization(z_pre_u, m, v)) #CHANGE\n","                      z += tf.random_normal(tf.shape(z_pre)) * noise_std\n","                  else:\n","                      # Clean encoder\n","                      # batch normalization + update the average mean and variance using batch mean and variance of\n","                      # labeled examples\n","                      z = join(update_batch_normalization(z_pre_l, l), batch_normalization(z_pre_u, m, v)) \n","                  return z\n","\n","              def eval_batch_norm():\n","                  # Evaluation batch normalization\n","                  # obtain average mean and variance and use it to normalize the batch\n","                  mean = ewma.average(running_mean[l-1])\n","                  var = ewma.average(running_var[l-1])\n","                  z = batch_normalization(z_pre, mean, var) \n","                  return z\n","              #If we are traning, use the training batch norm (we also have labeled data)\n","              z = tf.cond(training, training_batch_norm, eval_batch_norm)\n","\n","              if l == L:\n","                #Convert z and apply softmax for the last layer. (TODO: Only for prediction or if we pass through encoder?)\n","                h = tf.nn.softmax(weights['gamma'][l-1] * (z+weights['beta'][l-1]))\n","              elif l == L-1:\n","                h = tf.nn.relu(z + weights['beta'][l-1])\n","              else:\n","                h = tf.nn.relu(z + weights['beta'][l-1]) #TODO: No gamma?\n","\n","              #We split z and save the mean and variance of the unlabeled data for the decoder, where it is needed\n","              d['labeled']['z'][l], d['unlabeled']['z'][l] = split_lu(z)\n","              d['unlabeled']['m'][l], d['unlabeled']['v'][l] = m, v\n","          #Return the values at each layer. h is the output used (y) either corrupted or clean.\n","          d['labeled']['h'][l], d['unlabeled']['h'][l] = split_lu(h)\n","          return h, d\n","\n","        def get_activation(inputs,layer): #E.g. for last layer (not the 10 dim one) put L-1\n","          h = inputs + tf.random_normal(tf.shape(inputs)) * noise_std #Clean input if the noise std is set to zero\n","          d = {} #Store normalized preactivation z_l, h_l, mean, std\n","\n","          #Initialize the dictionary that stores the data. Note that the data is stored seperately\n","          #The speration is because we still want to know for which examples we have the labels\n","          d['labeled'] = {'z': {}, 'm': {}, 'v': {}, 'h': {}}\n","          d['unlabeled'] = {'z': {}, 'm': {}, 'v': {}, 'h': {}}\n","\n","          #Initialize the lowest layer with h. We do not have a transformation there.\n","          d['labeled']['z'][0], d['unlabeled']['z'][0] = split_lu(h)\n","          \n","          #Loop through all the layers. Doing forward propagation and updating the values we need to keep track of.\n","          for l in range(1, L+1): #Max. index: L\n","\n","              #print(\"Layer %s: ,%s -> %s\" % (l,architecture[l-1],architecture[l]))\n","              #Split the data that was joined before (TODO: Check if this can be done at end of loop)\n","              d['labeled']['h'][l-1], d['unlabeled']['h'][l-1] = split_lu(h)\n","              #Calculate the preactivation\n","              z_pre = tf.matmul(h, weights['W'][l-1])\n","              #Split into labeled and unlabeled examples\n","              z_pre_l, z_pre_u = split_lu(z_pre)\n","              #Caculate the mean and variance of the unlabeled examples, this is needed in the decoder phase when normalizing the \n","              m, v = tf.nn.moments(z_pre_u, axes=[0])\n","              m_l, v_l = tf.nn.moments(z_pre_l, axes=[0]) #CHANGE\n","\n","              #If we are traning, use the training batch norm (we also have labeled data)\n","              mean = ewma.average(running_mean[l-1])\n","              var = ewma.average(running_var[l-1])\n","              z = batch_normalization(z_pre, mean, var) \n","\n","              if l == L:\n","                #Convert z and apply softmax for the last layer. (TODO: Only for prediction or if we pass through encoder?)\n","                h = tf.nn.softmax(weights['gamma'][l-1] * (z+weights['beta'][l-1]))\n","                return h\n","              elif l == layer:\n","                h = tf.nn.relu(z + weights['beta'][l-1])\n","                return h\n","              else:\n","                h = tf.nn.relu(z + weights['beta'][l-1]) #TODO: No gamma?\n","\n","          \n","          \n","          \n","        last_layer_activation = get_activation(inputs, L-1)\n","        last_layer_activation = tf.identity(last_layer_activation, name='last_layer_activation')\n","          \n","        #Noise pass\n","        y_c, corr = encoder(inputs, noise_std)\n","        #Clean pass, do the clean pass after the noisy pass\n","        y, clean = encoder(inputs, 0.0)\n","        y = tf.identity(y, name=\"y\")\n","        \n","        #This is the function that performs the denoising  \n","        def g_gauss(z_c, u, size):\n","          wi = lambda inits, name: tf.Variable(inits * tf.ones([size]), name=name)\n","          a1 = wi(0., 'a1')\n","          a2 = wi(1., 'a2')\n","          a3 = wi(0., 'a3')\n","          a4 = wi(0., 'a4')\n","          a5 = wi(0., 'a5')\n","\n","          a6 = wi(0., 'a6')\n","          a7 = wi(1., 'a7')\n","          a8 = wi(0., 'a8')\n","          a9 = wi(0., 'a9')\n","          a10 = wi(0., 'a10')\n","\n","          mu = a1 * tf.sigmoid(a2 * u + a3) + a4 * u + a5\n","          v = a6 * tf.sigmoid(a7 * u + a8) + a9 * u + a10\n","\n","          z_est = (z_c - mu) * v + mu\n","          return z_est\n","\n","        #Decoder\n","        '''\n","        The decoder does the following:\n","        For l=L --> 0:\n","        If we are at the top (l==L) we do u <- batchnorm(h_L_corrupted)\n","        Else:\n","        u <- batchnorm(V*z_recon)\n","        What is z_recon?:  Take the previously u and the noisy z_l perform denoising function\n","        z_recon <- g(z_l_noisy, u_l) /// u_l was previously assigned\n","        z_recond_BN <- batch_normalize(z_recon_l, m, v) where m and v are the mean and variance from the layer z\n","        from the clean run.\n","        It is important to first make the corr. run and then the clean run. Otherwise we will use the\n","        m and v from the noisy run.\n","        '''\n","        z_est = {} #This corresponds to z_hat in the paper. This is not the batch normalize version\n","        d_cost = [] #Store the reconstruction cost of each layer\n","\n","        for l in range(L, -1, -1):\n","          #Get the clean and noisy layer values from the encoder run. z is used for reconstruction and\n","          #z_c is used for denoising (lateral connection) and z is used for cost function\n","          z, z_c = clean['unlabeled']['z'][l], corr['unlabeled']['z'][l]\n","          #Get the mean and variance from the clean run at the current layer l\n","          #TODO: Why only form the unlabeled data?\n","          m, v = clean['unlabeled']['m'].get(l, 0), clean['unlabeled']['v'].get(l, 1-1e-10)\n","          if l == L: #Initial assignment of u is the h_corr of the previous run through the encoder (noisy)\n","              u = unlabeled(y_c)\n","          else:\n","            #Just multiply with the weights and normalize the batch using the batch std and mean\n","            u = tf.matmul(z_est[l+1], weights['V'][l])\n","          u = batch_normalization(u)\n","          #Apply denoising function (lateral connection)  \n","          z_est[l] = g_gauss(z_c, u, architecture[l]) #TODO: Are these weights learned when we are reinit. the vars?\n","          z_est_bn = (z_est[l] - m) / v #Calculate the BN but don't save it. We only need it for the cost.\n","          #Append the cost of this layer to d_cost\n","          d_cost.append((tf.reduce_mean(tf.reduce_sum(tf.square(z_est_bn - z), 1)) / architecture[l]) * denoising_cost[l])\n","\n","\n","        #Calculate total unsupervised cost by adding the denoising cost of all layers\n","        u_cost = tf.add_n(d_cost)\n","\n","        #Use the corrupted output from the encoder as a prediction\n","        y_N = labeled(y_c)\n","        #Apply the supervised cost definition of true output * log(output noisy encoder + last layer)\n","        cost = -tf.reduce_mean(tf.reduce_sum(outputs*tf.log(y_N), 1))\n","        loss = cost + u_cost  # total cost\n","\n","        pred_cost = -tf.reduce_mean(tf.reduce_sum(outputs*tf.log(y), 1),name='pred_cost')  # cost used for prediction\n","\n","        #Use y for final classification. Use y_corr if we are training\n","        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(outputs, 1), name='correct_prediction')\n","        \n","        accuracy = tf.multiply(tf.reduce_mean(tf.cast(correct_prediction, \"float\")),tf.constant(100.0),name='accuracy')\n","        \n","        learning_rate = tf.Variable(lr, trainable=False)\n","        train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n","\n","        # add the updates of batch normalization statistics to train_step\n","        bn_updates = tf.group(*bn_assigns)\n","        with tf.control_dependencies([train_step]):\n","           train_step = tf.group(bn_updates)\n","\n","        if CHECKPOINT:\n","          saver = tf.train.Saver()\n","\n","        sess = tf.Session()\n","\n","        i_iter = 0\n","        if CHECKPOINT:\n","          ckpt = tf.train.get_checkpoint_state(c + '_checkpoints/')\n","          if ckpt and ckpt.model_checkpoint_path:\n","            print(\"Found checkpont! Restore...\")\n","            saver.restore(sess, ckpt.model_checkpoint_path)\n","            epoch_n = int(ckpt.model_checkpoint_path.split('-')[1])\n","            i_iter = (epoch_n+1) * (n_examples/batch_size)\n","            print(\"Restored Epoch %s\" % epoch_n)\n","          else:\n","            if not os.path.exists(c + '_checkpoints'):\n","              os.makedirs(c + '_checkpoints')\n","            init = tf.global_variables_initializer()\n","            sess.run(init)\n","        else:\n","          init = tf.global_variables_initializer()\n","          sess.run(init)\n","\n","        epoch_n = 0\n","        old_acc = 0.0\n","        for i in range(int(i_iter),num_iter):\n","          #Get the next batch of batch size (images and labels)\n","          images, labels = data.next_batch()\n","          sess.run(train_step, feed_dict={inputs: images, outputs: labels, training: True})\n","          if (i > 1) and ((i+1) % (num_iter//num_epochs) == 0):\n","            epoch_n = i // (n_examples//batch_size)\n","            acc = sess.run(accuracy, feed_dict={inputs: data.validate[0], outputs: data.validate[1], training: False})\n","            #print(\"Epoch: %s, Accuracy: %s\" % (epoch_n, acc))\n","            \n","            if (epoch_n+1) >= decay_after:\n","                # decay learning rate\n","                # learning_rate = starter_learning_rate * ((num_epochs - epoch_n) // (num_epochs - decay_after))\n","                ratio = 1.0 * (num_epochs - (epoch_n+1))  # epoch_n + 1 because learning rate is set for next epoch\n","                ratio = max(0, ratio // (num_epochs - decay_after))\n","                sess.run(learning_rate.assign(lr * ratio))\n","            if acc > old_acc:\n","              #print(\"Improved accuracy. Save...\")\n","              if CHECKPOINT: \n","                saver.save(sess, c + '_checkpoints/model.ckpt', epoch_n)\n","                model_inputs = {\n","                    \"inputs_placeholder\":inputs,\n","                    \"outputs_placeholder\":outputs\n","                }\n","                model_outputs = {\n","                    \"accuracy\": accuracy,\n","                    \"clean_output\": y,\n","                    \"last_layer_activation\": last_layer_activation\n","                }\n","                self.delete_models()\n","                tf.saved_model.simple_save(sess, c + '_models/',model_inputs,model_outputs)\n","                old_acc = acc\n","                \n","            #print(\"Created checkpoint.\")\n","        fa = sess.run(accuracy, feed_dict={inputs: data.test[0], outputs: data.test[1], training: False})    \n","        print(\"Final accuracy is: %s\" % fa)\n","        writer = tf.summary.FileWriter('./log/pshnn_ladder', sess.graph)\n","        \n","        model_inputs = {\n","            \"inputs_placeholder\":inputs,\n","            \"outputs_placeholder\":outputs\n","        }\n","        model_outputs = {\n","            \"accuracy\": accuracy,\n","            \"clean_output\": y,\n","            \"last_layer_activation\": last_layer_activation\n","        }\n","        self.delete_models()\n","        tf.saved_model.simple_save(sess, c + '_models/',model_inputs,model_outputs)\n","        return fa\n","        \n","        \n","  def predict(self,X,y=None):    \n","    c = str(self._id)\n","    from tensorflow.python.saved_model import tag_constants\n","    graph = tf.Graph()\n","    saver = tf.train.import_meta_graph(self.get_latest_meta())\n","    restored_graph = tf.get_default_graph()\n","    with restored_graph.as_default():\n","      with tf.Session() as sess:\n","        tf.saved_model.loader.load(\n","          sess,\n","          [tag_constants.SERVING],\n","          c + '_models/'  \n","        )\n","        inputs_placeholder = restored_graph.get_tensor_by_name('inputs:0')\n","        outputs_placeholder = restored_graph.get_tensor_by_name('outputs:0')    \n","        training = restored_graph.get_tensor_by_name('training:0')\n","        clean_output = restored_graph.get_tensor_by_name('y:0')\n","        \n","        out = sess.run(clean_output, feed_dict={inputs_placeholder: X, training:False})\n","        res = [np.argmax(out[i]) for i in range(out.shape[0])]\n","        if y is not None:\n","          accuracy = restored_graph.get_tensor_by_name('accuracy:0')\n","          acc = sess.run(accuracy, feed_dict={inputs_placeholder: X, outputs_placeholder: to_categorical(y), training:False})\n","          return (np.asarray(res),acc)\n","        else:\n","          return np.asarray(res)\n","   \n","  def get_last_layer_activation(self,X,dim):\n","    c = str(self._id)\n","    act = np.zeros((X.shape[0],dim))\n","    from tensorflow.python.saved_model import tag_constants\n","    graph = tf.Graph()\n","    saver = tf.train.import_meta_graph(self.get_latest_meta())\n","    restored_graph = tf.get_default_graph()\n","    with restored_graph.as_default():\n","      with tf.Session() as sess:\n","        tf.saved_model.loader.load(\n","          sess,\n","          [tag_constants.SERVING],\n","          c + '_models/'  \n","        )\n","        inputs_placeholder = restored_graph.get_tensor_by_name('inputs:0')\n","        outputs_placeholder = restored_graph.get_tensor_by_name('outputs:0')    \n","        training = restored_graph.get_tensor_by_name('training:0')\n","        last_layer_activation = restored_graph.get_tensor_by_name('last_layer_activation:0')\n","        out = sess.run(last_layer_activation, feed_dict={inputs_placeholder: X, training:False})\n","        return out\n","        \n","    \n","  def get_activation(self,X):  \n","    c = str(self._id)\n","    from tensorflow.python.saved_model import tag_constants\n","    graph = tf.Graph()\n","    saver = tf.train.import_meta_graph(self.get_latest_meta())\n","    restored_graph = tf.get_default_graph()\n","    with restored_graph.as_default():\n","      with tf.Session() as sess:\n","        tf.saved_model.loader.load(\n","          sess,\n","          [tag_constants.SERVING],\n","          c + '_models/'  \n","        )\n","        inputs_placeholder = restored_graph.get_tensor_by_name('inputs:0')\n","        outputs_placeholder = restored_graph.get_tensor_by_name('outputs:0')    \n","        training = restored_graph.get_tensor_by_name('training:0')\n","        clean_output = restored_graph.get_tensor_by_name('y:0')\n","        out = sess.run(clean_output, feed_dict={inputs_placeholder: X, training:False})\n","        return out\n","      \n","      \n","      \n","import numpy as np\n","import scipy.stats\n","\n","\n","def mean_confidence_interval(data, confidence=0.95):\n","    a = 1.0 * np.array(data)\n","    n = len(a)\n","    m, se = np.mean(a), scipy.stats.sem(a)\n","    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n","    return m, m-h, m+h"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Using Theano backend.\n"],"name":"stderr"}]},{"metadata":{"id":"JqceUM_amuio","colab_type":"code","outputId":"ae106131-5cad-49a3-dcab-090ba4940b8e","executionInfo":{"status":"error","timestamp":1542901657890,"user_tz":300,"elapsed":13145,"user":{"displayName":"Julian Büchel","photoUrl":"https://lh3.googleusercontent.com/-bqF5uYHav44/AAAAAAAAAAI/AAAAAAAAABI/I52w6WAUfGc/s64/photo.jpg","userId":"08269725658623338909"}},"colab":{"base_uri":"https://localhost:8080/","height":2819}},"cell_type":"code","source":["#Pavia pipeline\n","# nl = [45,90,270,450,-1]\n","# bs = [45,90,100,100,100]\n","# nc = [-1,-1,-1,-1,30]\n","nl = [15]\n","bs = [135]\n","nc = [-1]\n","\n","epochs = 20\n","noise_std = 0.1\n","learning_rate = 0.005\n","decay_after = 30\n","\n","CHECKPOINT = True\n","\n","for j in range(5):\n","  num_labeled = nl[j]\n","  batch_size = bs[j]\n","  n_components = nc[j]\n","\n","  accuracies = []\n","  for _ in range(20):\n","\n","    if n_components == -1:\n","      fd = 103\n","    else: fd = n_components\n","    ds = preprocess_data('pavia',n_components,[fd,300,200,100,100,9],[10.0,1.0,0.1,0.1,0.1,0.1],batch_size,num_labeled)\n","\n","    #If running for the first time, comment out the following two lines.\n","    #nn.delete_checkpoints()\n","    #nn.delete_models()\n","    tf.logging.set_verbosity(tf.logging.WARN)\n","    nn = LadderNetwork(1)\n","\n","    acc = nn.train(ds,epochs,num_labeled,noise_std,learning_rate,decay_after)\n","    accuracies += [acc]\n","    print(accuracies)\n","    \n","  mean, lo, hi = mean_confidence_interval(accuracies)\n","  print(\"Confidence interval is [%s ; %s ; %s]\" % (lo,mean,hi))    \n","  \n","\n","  \n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype uint16 was converted to float64 by StandardScaler.\n","  warnings.warn(msg, DataConversionWarning)\n"],"name":"stderr"},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [9,9] vs. [135,9]\n\t [[{{node gradients/mul_123_grad/BroadcastGradientArgs}} = BroadcastGradientArgs[T=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](gradients/mul_123_grad/Shape, gradients/cond_9/moments/SquaredDifference_grad/Shape)]]","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-133c43f47bd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLadderNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_labeled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnoise_std\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecay_after\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0maccuracies\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-e6237a670c60>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data, num_epochs, num_labeled, noise_std, lr, decay_after)\u001b[0m\n\u001b[1;32m    383\u001b[0m           \u001b[0;31m#Get the next batch of batch size (images and labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m           \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m           \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_iter\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mepoch_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_examples\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [9,9] vs. [135,9]\n\t [[node gradients/mul_123_grad/BroadcastGradientArgs (defined at <ipython-input-4-e6237a670c60>:350)  = BroadcastGradientArgs[T=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](gradients/mul_123_grad/Shape, gradients/cond_9/moments/SquaredDifference_grad/Shape)]]\n\nCaused by op 'gradients/mul_123_grad/BroadcastGradientArgs', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-133c43f47bd5>\", line 31, in <module>\n    acc = nn.train(ds,epochs,num_labeled,noise_std,learning_rate,decay_after)\n  File \"<ipython-input-4-e6237a670c60>\", line 350, in train\n    train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/optimizer.py\", line 400, in minimize\n    grad_loss=grad_loss)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/optimizer.py\", line 519, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 630, in gradients\n    gate_gradients, aggregation_method, stop_gradients)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 814, in _GradientsHelper\n    lambda: grad_fn(op, *out_grads))\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 408, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 814, in <lambda>\n    lambda: grad_fn(op, *out_grads))\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py\", line 940, in _MulGrad\n    rx, ry = gen_array_ops.broadcast_gradient_args(sx, sy)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 676, in broadcast_gradient_args\n    \"BroadcastGradientArgs\", s0=s0, s1=s1, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\n...which was originally created as op 'mul_123', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 18 identical lines from previous traceback]\n  File \"<ipython-input-10-133c43f47bd5>\", line 31, in <module>\n    acc = nn.train(ds,epochs,num_labeled,noise_std,learning_rate,decay_after)\n  File \"<ipython-input-4-e6237a670c60>\", line 339, in train\n    cost = -tf.reduce_mean(tf.reduce_sum(outputs*tf.log(y_N), 1))\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\", line 866, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\", line 1131, in _mul_dispatch\n    return gen_math_ops.mul(x, y, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 5042, in mul\n    \"Mul\", x=x, y=y, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [9,9] vs. [135,9]\n\t [[node gradients/mul_123_grad/BroadcastGradientArgs (defined at <ipython-input-4-e6237a670c60>:350)  = BroadcastGradientArgs[T=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](gradients/mul_123_grad/Shape, gradients/cond_9/moments/SquaredDifference_grad/Shape)]]\n"]}]},{"metadata":{"id":"R7uLGZwg4a6K","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}